{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in c:\\users\\user1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\user1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from bs4) (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\user1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from beautifulsoup4->bs4) (2.3.2.post1)\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for the file and replace check is not tested\n",
    "def getData():\n",
    "    # import the file \n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    #initalize to array \n",
    "    name = []\n",
    "    prices = []\n",
    "    # link for the crude oil to get the data\n",
    "    urlCrud = 'https://finance.yahoo.com/quote/CL%3DF'\n",
    "    # tag to get the prices from the page\n",
    "    tagValue = 'div'\n",
    "    tagName = 'h1'\n",
    "    # using class as the identifier to get the value from specific section\n",
    "    findValue = {\"class\":\"D(ib) Mend(20px)\"}\n",
    "    findName = {\"class\":\"D(ib) Fz(18px)\"}\n",
    "    # request the page using the url\n",
    "    respOil = requests.get(url= urlCrud)\n",
    "    # this will parse in the html file\n",
    "    beautifyOil = BeautifulSoup(respOil.text,'html.parser')\n",
    "    # find the tag with class to get the value as name\n",
    "    nameC = beautifyOil.find(tagName,findName).text\n",
    "    # use find the to go to the section which has value iterate over all and observed the first one will return price\n",
    "    priceOil = beautifyOil.find(tagValue,findValue).find_all('fin-streamer')[0].text\n",
    "    # append to the array\n",
    "    name.append(nameC)\n",
    "    prices.append(priceOil)\n",
    "\n",
    "    # link for the Gold to get the data\n",
    "    urlGold = 'https://finance.yahoo.com/quote/GC=F'\n",
    "    # request the page using the url\n",
    "    respGold = requests.get(url= urlGold)\n",
    "    # this will parse in the html file\n",
    "    beautifyGold = BeautifulSoup(respGold.text,'html.parser')\n",
    "    # find the tag with class to get the value as name\n",
    "    nameG = beautifyGold.find(tagName,findName).text\n",
    "    # use find the to go to the section which has value iterate over all and observed the first one will return price\n",
    "    priceGold = beautifyGold.find(tagValue,findValue).find_all('fin-streamer')[0].text\n",
    "    # append to the array\n",
    "    name.append(nameG)\n",
    "    prices.append(priceGold)\n",
    "\n",
    "    # link for the Gold to get the data\n",
    "    urlSilver = 'https://finance.yahoo.com/quote/SI=F'\n",
    "    # request the page using the url\n",
    "    respSilver = requests.get(url= urlSilver)\n",
    "    # this will parse in the html file\n",
    "    beautifysilver = BeautifulSoup(respSilver.text,'html.parser')\n",
    "    # find the tag with class to get the value as name\n",
    "    nameS = beautifysilver.find(tagName,findName).text\n",
    "    # use find the to go to the section which has value iterate over all and observed the first one will return price\n",
    "    priceSilver = beautifysilver.find(tagValue,findValue).find_all('fin-streamer')[0].text\n",
    "    # append to the array\n",
    "    name.append(nameS)\n",
    "    prices.append(priceSilver)\n",
    "    return name,prices\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function parameter is name and price array\n",
    "def generateFile(name,prices):\n",
    "    f = open('commodity_prices.txt', 'w+') # open the file with write mode\n",
    "    f.write(\"Commodity\\t:\" + \"\\tPrices\\n\") # write column name in the array\n",
    "    for i in range(len(name)): #iterate over name and prices array\n",
    "        f.write( name[i] +\"\\t:\\t\" + prices[i] +\"\\n\")\n",
    "    f.close()    # close once the data is written"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function will create connection with the sqlite3\n",
    "def createConnection():\n",
    "    import sqlite3\n",
    "# specify the schema name\n",
    "    conn = sqlite3.connect('CommodityDatabase.sqlite')\n",
    "    # create a cursor \n",
    "    cur = conn.cursor()\n",
    "    # check if the table exists if yes then drop\n",
    "    cur.execute(\"DROP TABLE IF EXISTS CommodityTable\")\n",
    "    # create a new table to store data wint ticker and price as name of columns\n",
    "    cur.execute('CREATE TABLE CommodityTable (Ticker TEXT, Price REAL)')\n",
    "    # commit the change and return the connection object\n",
    "    conn.commit()\n",
    "    return  conn\n",
    "def insertValue(conn,val):    \n",
    "    # using the connection object and values insert into the table\n",
    "    sql = ''' INSERT INTO CommodityTable(Ticker,Price)VALUES(?,?) '''\n",
    "    # create cursor instance\n",
    "    cur = conn.cursor()\n",
    "    #execute the query\n",
    "    cur.execute(sql, val)\n",
    "    # commit the changes\n",
    "    conn.commit()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['72.78', '1,794.90', '22.80']\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    name,prices = getData()\n",
    "    generateFile(name,prices)\n",
    "    con = createConnection()\n",
    "    for i in range(len(name)):\n",
    "        val = (name[i],prices[i])\n",
    "        insertValue(con,val)\n",
    "    con.close()    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting yahoo_fin\n",
      "  Downloading yahoo_fin-0.8.9.1-py3-none-any.whl (10 kB)\n",
      "Collecting feedparser\n",
      "  Downloading feedparser-6.0.10-py3-none-any.whl (81 kB)\n",
      "     ---------------------------------------- 81.1/81.1 kB 2.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests in c:\\users\\user1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from yahoo_fin) (2.28.1)\n",
      "Collecting requests-html\n",
      "  Downloading requests_html-0.10.0-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\user1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from yahoo_fin) (1.5.0)\n",
      "Collecting sgmllib3k\n",
      "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\user1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->yahoo_fin) (1.23.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->yahoo_fin) (2022.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\user1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->yahoo_fin) (2.8.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->yahoo_fin) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\user1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->yahoo_fin) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->yahoo_fin) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->yahoo_fin) (2022.9.24)\n",
      "Collecting pyquery\n",
      "  Downloading pyquery-1.4.3-py3-none-any.whl (22 kB)\n",
      "Collecting w3lib\n",
      "  Downloading w3lib-2.1.0-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: bs4 in c:\\users\\user1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests-html->yahoo_fin) (0.0.1)\n",
      "Collecting pyppeteer>=0.0.14\n",
      "  Downloading pyppeteer-1.0.2-py3-none-any.whl (83 kB)\n",
      "     ---------------------------------------- 83.4/83.4 kB 4.6 MB/s eta 0:00:00\n",
      "Collecting parse\n",
      "  Downloading parse-1.19.0.tar.gz (30 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting fake-useragent\n",
      "  Downloading fake_useragent-1.1.1-py3-none-any.whl (50 kB)\n",
      "     ---------------------------------------- 50.4/50.4 kB 2.7 MB/s eta 0:00:00\n",
      "Collecting importlib-metadata>=1.4\n",
      "  Downloading importlib_metadata-5.1.0-py3-none-any.whl (21 kB)\n",
      "Collecting appdirs<2.0.0,>=1.4.3\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting pyee<9.0.0,>=8.1.0\n",
      "  Downloading pyee-8.2.2-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.42.1 in c:\\users\\user1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyppeteer>=0.0.14->requests-html->yahoo_fin) (4.64.1)\n",
      "Collecting websockets<11.0,>=10.0\n",
      "  Downloading websockets-10.4-cp310-cp310-win_amd64.whl (101 kB)\n",
      "     -------------------------------------- 101.4/101.4 kB 6.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->yahoo_fin) (1.16.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\user1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from bs4->requests-html->yahoo_fin) (4.11.1)\n",
      "Collecting cssselect>0.7.9\n",
      "  Downloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting lxml>=2.1\n",
      "  Downloading lxml-4.9.1-cp310-cp310-win_amd64.whl (3.6 MB)\n",
      "     ---------------------------------------- 3.6/3.6 MB 16.3 MB/s eta 0:00:00\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.11.0-py3-none-any.whl (6.6 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\user1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm<5.0.0,>=4.42.1->pyppeteer>=0.0.14->requests-html->yahoo_fin) (0.4.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\user1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from beautifulsoup4->bs4->requests-html->yahoo_fin) (2.3.2.post1)\n",
      "Building wheels for collected packages: parse, sgmllib3k\n",
      "  Building wheel for parse (setup.py): started\n",
      "  Building wheel for parse (setup.py): finished with status 'done'\n",
      "  Created wheel for parse: filename=parse-1.19.0-py3-none-any.whl size=24657 sha256=c9767fe1dc4d65af93b52cfa6a97489145186476715c4f8acd79d091f99ec9db\n",
      "  Stored in directory: c:\\users\\user1\\appdata\\local\\pip\\cache\\wheels\\03\\d9\\92\\db136347b5bcba7d271a3c042ce8c9c279e0ecd79173bb0a6e\n",
      "  Building wheel for sgmllib3k (setup.py): started\n",
      "  Building wheel for sgmllib3k (setup.py): finished with status 'done'\n",
      "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6078 sha256=19a8407347531cefdc0d78bb0a10720c502d8448b4fe5fa5772916a93170e492\n",
      "  Stored in directory: c:\\users\\user1\\appdata\\local\\pip\\cache\\wheels\\3b\\24\\68\\f82c1fe16fe6cc7c6f9f67fe4bbf2a4ce527dea6b14a4b34ee\n",
      "Successfully built parse sgmllib3k\n",
      "Installing collected packages: sgmllib3k, pyee, parse, fake-useragent, appdirs, zipp, websockets, w3lib, lxml, feedparser, cssselect, pyquery, importlib-metadata, pyppeteer, requests-html, yahoo_fin\n",
      "Successfully installed appdirs-1.4.4 cssselect-1.2.0 fake-useragent-1.1.1 feedparser-6.0.10 importlib-metadata-5.1.0 lxml-4.9.1 parse-1.19.0 pyee-8.2.2 pyppeteer-1.0.2 pyquery-1.4.3 requests-html-0.10.0 sgmllib3k-1.0.0 w3lib-2.1.0 websockets-10.4 yahoo_fin-0.8.9.1 zipp-3.11.0\n"
     ]
    }
   ],
   "source": [
    "!pip install yahoo_fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72.72000122070312"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from yahoo_fin import stock_info as si\n",
    "si.get_live_price(\"CL%3DF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4b158de9dee9cdd12df4ca6f07919f74aba3858e0415eb8802c7bdbce4de9a36"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
